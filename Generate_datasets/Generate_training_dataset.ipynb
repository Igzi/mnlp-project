{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ee9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, concatenate_datasets, Dataset\n",
    "\n",
    "mmlu_auxiliary_data = []\n",
    "arc_easy_data = []\n",
    "arc_challenge_data = []\n",
    "scienceqa_data = []\n",
    "mathqa_data = []\n",
    "openbookqa_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd09b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of STEM-related MMLU subsets\n",
    "stem_subsets = [\n",
    "    \"abstract_algebra\",\n",
    "    \"anatomy\",\n",
    "    \"astronomy\",\n",
    "    \"college_biology\",\n",
    "    \"college_chemistry\",\n",
    "    \"college_computer_science\",\n",
    "    \"college_mathematics\",\n",
    "    \"college_physics\",\n",
    "    \"computer_security\",\n",
    "    \"conceptual_physics\",\n",
    "    \"electrical_engineering\",\n",
    "    \"elementary_mathematics\",\n",
    "    \"high_school_biology\",\n",
    "    \"high_school_chemistry\",\n",
    "    \"high_school_computer_science\",\n",
    "    \"high_school_mathematics\",\n",
    "    \"high_school_physics\",\n",
    "    \"high_school_statistics\",\n",
    "    \"machine_learning\",\n",
    "]\n",
    "\n",
    "data = load_dataset(\"kz919/mmlu-auxiliary-train-auto-labelled\", split=\"train\")\n",
    "int_to_char_ans = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}\n",
    "cnt = 0\n",
    "for data_point in data:\n",
    "    if data_point[\"task\"] not in stem_subsets:\n",
    "        continue\n",
    "    mmlu_auxiliary_data.append({\n",
    "        \"dataset\": \"kz919/mmlu-auxiliary-train-auto-labelled\",\n",
    "        \"id\": f\"mmlu_auxiliary_train_auto_labelled_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"],\n",
    "        \"answer\": int_to_char_ans[data_point[\"answer\"]]\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab0f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"cais/mmlu\", 'all', split=\"validation\")\n",
    "int_to_char_ans = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}\n",
    "cnt = 0\n",
    "mmlu_validation_data = []\n",
    "for data_point in data:\n",
    "    if data_point[\"subject\"] not in stem_subsets:\n",
    "        continue\n",
    "    mmlu_validation_data.append({\n",
    "        \"dataset\": \"cais/mmlu\",\n",
    "        \"id\": f\"mmlu_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"],\n",
    "        \"answer\": int_to_char_ans[data_point[\"answer\"]]\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3022767-b565-46de-888a-786bcc1be73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset, Dataset\n",
    "# from collections import defaultdict\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# # STEM-related MMLU subsets\n",
    "# stem_subsets = [\n",
    "#     \"abstract_algebra\",\n",
    "#     \"anatomy\",\n",
    "#     \"astronomy\",\n",
    "#     \"college_biology\",\n",
    "#     \"college_chemistry\",\n",
    "#     \"college_computer_science\",\n",
    "#     \"college_mathematics\",\n",
    "#     \"college_physics\",\n",
    "#     \"computer_security\",\n",
    "#     \"conceptual_physics\",\n",
    "#     \"electrical_engineering\",\n",
    "#     \"elementary_mathematics\",\n",
    "#     \"high_school_biology\",\n",
    "#     \"high_school_chemistry\",\n",
    "#     \"high_school_computer_science\",\n",
    "#     \"high_school_mathematics\",\n",
    "#     \"high_school_physics\",\n",
    "#     \"high_school_statistics\",\n",
    "#     \"machine_learning\",\n",
    "# ]\n",
    "\n",
    "# data = load_dataset(\"kz919/mmlu-auxiliary-train-auto-labelled\", split=\"train\")\n",
    "\n",
    "# # Build subject-wise pool of all unique choices\n",
    "# subject2options = defaultdict(set)\n",
    "# for item in data:\n",
    "#     if item[\"task\"] in stem_subsets:\n",
    "#         subject2options[item[\"task\"]].update(item[\"choices\"])\n",
    "# subject2options = {k: list(v) for k, v in subject2options.items()}\n",
    "\n",
    "# mmlu_stem_10 = []\n",
    "# cnt = 0\n",
    "\n",
    "# for item in tqdm(data, desc=\"Processing STEM items\"):\n",
    "#     subject = item[\"task\"]\n",
    "#     if subject not in stem_subsets:\n",
    "#         continue\n",
    "\n",
    "#     orig_choices = item[\"choices\"]\n",
    "#     correct_ans_idx = item[\"answer\"]\n",
    "#     correct_ans_text = orig_choices[correct_ans_idx]\n",
    "\n",
    "#     # Distractor pool: same subject, exclude all current choices\n",
    "#     distractor_pool = [opt for opt in subject2options[subject] if opt not in orig_choices]\n",
    "\n",
    "#     needed = 10 - len(orig_choices)\n",
    "#     if len(distractor_pool) < needed:\n",
    "#         distractors = random.choices(distractor_pool, k=needed)  # with replacement if necessary\n",
    "#     else:\n",
    "#         distractors = random.sample(distractor_pool, needed)\n",
    "\n",
    "#     expanded_choices = orig_choices + distractors\n",
    "#     random.shuffle(expanded_choices)\n",
    "#     new_correct_idx = expanded_choices.index(correct_ans_text)\n",
    "#     answer_letter = chr(ord(\"A\") + new_correct_idx)\n",
    "\n",
    "#     mmlu_stem_10.append({\n",
    "#         \"dataset\": \"kz919/mmlu-auxiliary-train-auto-labelled\",\n",
    "#         \"id\": f\"mmlu_auxiliary_train_auto_labelled_10_options{cnt}\",\n",
    "#         \"question\": item[\"question\"],\n",
    "#         \"choices\": expanded_choices,\n",
    "#         \"answer\": answer_letter,\n",
    "#     })\n",
    "#     cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51b28c5-6c28-4b0a-8f34-698cb4a7256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"andresnowak/mmlu-auxiliary-train-10-choices\", split=\"train\")\n",
    "cnt = 0\n",
    "mmlu_stem_10 = []\n",
    "for data_point in data:\n",
    "    mmlu_stem_10.append({\n",
    "        \"dataset\": \"kz919/mmlu-auxiliary-train-auto-labelled\",\n",
    "        \"id\": f\"mmlu_auxiliary_train_auto_labelled_10_choices_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"10_choices\"],\n",
    "        \"answer\": data_point[\"answer_10_choices_letter\"]\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5db51-7fad-42fe-8fc5-9505bbb00a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_validation_data_10 = None\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# stem_categories = [\n",
    "#     \"math\",\n",
    "#     \"engineering\",\n",
    "#     \"computer science\",\n",
    "# ]\n",
    "\n",
    "# # Load MMLU-Pro dataset (test split)\n",
    "# dataset = load_dataset(\"TIGER-Lab/MMLU-Pro\", split=\"test\")\n",
    "\n",
    "# # Filter for STEM categories\n",
    "# def filter_stem(example):\n",
    "#     return example['category'] in stem_categories\n",
    "\n",
    "# stem_dataset = dataset.filter(filter_stem)\n",
    "\n",
    "# cnt = 0\n",
    "# mmlu_validation_data_10 = []\n",
    "\n",
    "# for data_point in stem_dataset:\n",
    "#     mmlu_validation_data_10.append({\n",
    "#         \"dataset\": \"TIGER-Lab/MMLU-Pro\",\n",
    "#         \"id\": f\"mmlu_pro_{cnt}\",\n",
    "#         \"question\": data_point[\"question\"],\n",
    "#         \"choices\": data_point[\"options\"],\n",
    "#         \"answer\": data_point[\"answer\"]\n",
    "#     })\n",
    "#     cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d638e3-8c6a-46f7-94e7-9ad77725ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\", split=\"train\")\n",
    "for data_point in data:\n",
    "    if not 'A' <= data_point[\"answerKey\"] <= 'Z':\n",
    "        if data_point[\"answerKey\"] == \"0\":\n",
    "            print(\"ERROR\")\n",
    "        # Convert numeric string to int and then to letter\n",
    "        c = chr(int(data_point[\"answerKey\"]) + ord('A')-1)\n",
    "        data_point[\"answerKey\"] = c\n",
    "\n",
    "    arc_easy_data.append({\n",
    "        \"dataset\": \"allenai/ai2_arc\",\n",
    "        \"id\": f\"arc_easy_{data_point['id']}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"][\"text\"],\n",
    "        \"answer\": data_point[\"answerKey\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea7480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\", split=\"validation\")\n",
    "arc_easy_data_validation = []\n",
    "for data_point in data:\n",
    "    if not 'A' <= data_point[\"answerKey\"] <= 'Z':\n",
    "        if data_point[\"answerKey\"] == \"0\":\n",
    "            print(\"ERROR\")\n",
    "        # Convert numeric string to int and then to letter\n",
    "        c = chr(int(data_point[\"answerKey\"]) + ord('A')-1)\n",
    "        data_point[\"answerKey\"] = c\n",
    "    arc_easy_data_validation.append({\n",
    "        \"dataset\": \"allenai/ai2_arc\",\n",
    "        \"id\": f\"arc_easy_{data_point['id']}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"][\"text\"],\n",
    "        \"answer\": data_point[\"answerKey\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076a628a-ce91-4345-a222-517323b0f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\", split=\"train\")\n",
    "for data_point in data:\n",
    "    if not 'A' <= data_point[\"answerKey\"] <= 'Z':\n",
    "        if data_point[\"answerKey\"] == \"0\":\n",
    "            print(\"ERROR\")\n",
    "        # Convert numeric string to int and then to letter\n",
    "        c = chr(int(data_point[\"answerKey\"]) + ord('A')-1)\n",
    "        data_point[\"answerKey\"] = c\n",
    "\n",
    "    arc_challenge_data.append({\n",
    "        \"dataset\": \"allenai/ai2_arc\",\n",
    "        \"id\": f\"arc_challenge_{data_point['id']}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"][\"text\"],\n",
    "        \"answer\": data_point[\"answerKey\"]\n",
    "    })\n",
    "\n",
    "data = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\", split=\"validation\")\n",
    "arc_challenge_data_validation = []\n",
    "for data_point in data:\n",
    "    if not 'A' <= data_point[\"answerKey\"] <= 'Z':\n",
    "        if data_point[\"answerKey\"] == \"0\":\n",
    "            print(\"ERROR\")\n",
    "        # Convert numeric string to int and then to letter\n",
    "        c = chr(int(data_point[\"answerKey\"]) + ord('A')-1)\n",
    "        data_point[\"answerKey\"] = c\n",
    "    arc_challenge_data_validation.append({\n",
    "        \"dataset\": \"allenai/ai2_arc\",\n",
    "        \"id\": f\"arc_challenge_{data_point['id']}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"][\"text\"],\n",
    "        \"answer\": data_point[\"answerKey\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6647343-23d0-4465-927d-410b07bde0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"derek-thomas/ScienceQA\", split=\"train\")\n",
    "cnt = 0\n",
    "for data_point in data:\n",
    "    if data_point[\"image\"] is not None or data_point[\"subject\"] != \"natural science\" or data_point[\"task\"] != \"closed choice\":\n",
    "        continue\n",
    "    scienceqa_data.append({\n",
    "        \"dataset\": \"derek-thomas/ScienceQA\",\n",
    "        \"id\": f\"scienceqa_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"],\n",
    "        \"answer\": int_to_char_ans[data_point[\"answer\"]]\n",
    "    })\n",
    "    cnt += 1\n",
    "\n",
    "data = load_dataset(\"derek-thomas/ScienceQA\", split=\"test\")\n",
    "cnt = 0\n",
    "for data_point in data:\n",
    "    if data_point[\"image\"] is not None or data_point[\"subject\"] != \"natural science\" or data_point[\"task\"] != \"closed choice\":\n",
    "        continue\n",
    "    scienceqa_data.append({\n",
    "        \"dataset\": \"derek-thomas/ScienceQA\",\n",
    "        \"id\": f\"scienceqa_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"],\n",
    "        \"answer\": int_to_char_ans[data_point[\"answer\"]]\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0998ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"derek-thomas/ScienceQA\", split=\"validation\")\n",
    "cnt = 0\n",
    "scienceqa_data_validation = []\n",
    "for data_point in data:\n",
    "    if data_point[\"image\"] is not None or data_point[\"subject\"] != \"natural science\" or data_point[\"task\"] != \"closed choice\":\n",
    "        continue\n",
    "    scienceqa_data_validation.append({\n",
    "        \"dataset\": \"derek-thomas/ScienceQA\",\n",
    "        \"id\": f\"scienceqa_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": data_point[\"choices\"],\n",
    "        \"answer\": int_to_char_ans[data_point[\"answer\"]]\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1980068-47af-4cc6-993b-27c9a48a6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data = load_dataset(\"allenai/math_qa\", split=\"train\")\n",
    "cnt = 0\n",
    "char_to_char_ans = {\n",
    "    'a': \"A\",\n",
    "    'b': \"B\",\n",
    "    'c': \"C\",\n",
    "    'd': \"D\",\n",
    "    'e': \"E\"\n",
    "}\n",
    "\n",
    "def extract_choices(choices_str):\n",
    "    matches = re.findall(r'[a-e]\\s*\\)\\s*([^,]+)', choices_str)\n",
    "    # Clean up whitespace and dots\n",
    "    res = [m.strip().replace(' .', '.').replace(' ,', ',') for m in matches]\n",
    "    return res\n",
    "\n",
    "for data_point in data:\n",
    "    mathqa_data.append({\n",
    "        \"dataset\": \"allenai/math_qa\",\n",
    "        \"id\": f\"mathqa_{cnt}\",\n",
    "        \"question\": data_point[\"Problem\"],\n",
    "        \"choices\": extract_choices(data_point[\"options\"]),\n",
    "        \"answer\": char_to_char_ans[data_point[\"correct\"]],\n",
    "        \"context\": data_point[\"Rationale\"],\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae522f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"allenai/math_qa\", split=\"validation\")\n",
    "cnt = 0\n",
    "\n",
    "mathqa_data_validation = []\n",
    "\n",
    "for data_point in data:\n",
    "    mathqa_data_validation.append({\n",
    "        \"dataset\": \"allenai/math_qa\",\n",
    "        \"id\": f\"mathqa_{cnt}\",\n",
    "        \"question\": data_point[\"Problem\"],\n",
    "        \"choices\": extract_choices(data_point[\"options\"]),\n",
    "        \"answer\": char_to_char_ans[data_point[\"correct\"]],\n",
    "        \"context\": data_point[\"Rationale\"],\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ead71f-9cd6-4ab8-a820-1f3a6faf565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"allenai/openbookqa\", \"additional\", split=\"train\")\n",
    "cnt = 0\n",
    "\n",
    "openbookqa_data = []\n",
    "\n",
    "for data_point in data:\n",
    "    openbookqa_data.append({\n",
    "        \"dataset\": \"allenai/openbookqa\",\n",
    "        \"id\": f\"openbookqa_{cnt}\",\n",
    "        \"question\": data_point[\"question_stem\"],\n",
    "        \"choices\": data_point[\"choices\"][\"text\"],\n",
    "        \"answer\": data_point[\"answerKey\"],\n",
    "        \"context\": data_point[\"fact1\"],\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2508cfcf-7b32-40c6-b366-59a0492991d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"allenai/openbookqa\", \"additional\", split=\"validation\")\n",
    "cnt = 0\n",
    "\n",
    "openbookqa_data_validation = []\n",
    "\n",
    "for data_point in data:\n",
    "    openbookqa_data_validation.append({\n",
    "        \"dataset\": \"allenai/openbookqa\",\n",
    "        \"id\": f\"openbookqa_{cnt}\",\n",
    "        \"question\": data_point[\"question_stem\"],\n",
    "        \"choices\": data_point[\"choices\"][\"text\"],\n",
    "        \"answer\": data_point[\"answerKey\"],\n",
    "        \"context\": data_point[\"fact1\"],\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa4100ae-40bf-4ac4-890b-eaeb8e88e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data = load_dataset(\"allenai/sciq\", split=\"train\")\n",
    "cnt = 0\n",
    "\n",
    "sciq_data_train = []\n",
    "int_to_char_ans = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}\n",
    "\n",
    "for data_point in data:\n",
    "    options = [data_point[\"correct_answer\"], data_point[\"distractor1\"], data_point[\"distractor2\"], data_point[\"distractor3\"]]\n",
    "    gold_ix = random.randint(0, 3)\n",
    "    options[0], options[gold_ix] = options[gold_ix], options[0]\n",
    "    sciq_data_train.append({\n",
    "        \"dataset\": \"allenai/sciq\",\n",
    "        \"id\": f\"sciq_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": options,\n",
    "        \"answer\": int_to_char_ans[gold_ix],\n",
    "        \"context\": data_point[\"support\"],\n",
    "    })\n",
    "    cnt += 1\n",
    "\n",
    "data = load_dataset(\"allenai/sciq\", split=\"validation\")\n",
    "sciq_data_validation = []\n",
    "cnt = 0\n",
    "\n",
    "for data_point in data:\n",
    "    options = [data_point[\"correct_answer\"], data_point[\"distractor1\"], data_point[\"distractor2\"], data_point[\"distractor3\"]]\n",
    "    gold_ix = random.randint(0, 3)\n",
    "    options[0], options[gold_ix] = options[gold_ix], options[0]\n",
    "    sciq_data_validation.append({\n",
    "        \"dataset\": \"allenai/sciq\",\n",
    "        \"id\": f\"sciq_{cnt}\",\n",
    "        \"question\": data_point[\"question\"],\n",
    "        \"choices\": options,\n",
    "        \"answer\": int_to_char_ans[gold_ix],\n",
    "        \"context\": data_point[\"support\"],\n",
    "    })\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c5082c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_hf(subset_name, train_dataset, validation_dataset=None):\n",
    "    train_dataset = Dataset.from_list(train_dataset)\n",
    "    if validation_dataset is not None:\n",
    "        validation_dataset = Dataset.from_list(validation_dataset)\n",
    "        dataset_dict = DatasetDict({\n",
    "            \"train\": train_dataset,\n",
    "            \"validation\": validation_dataset\n",
    "        })\n",
    "    else:\n",
    "        dataset_dict = DatasetDict({\n",
    "            \"train\": train_dataset\n",
    "        })\n",
    "    dataset_dict.push_to_hub(\"igzi/MNLP_M3_rag_dataset\", config_name=subset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eed722b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd6475bbf8e45dd916621c8f50fb9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7373fe23cf4335b742568230f7e458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c462df03f44f0eb25cc758d3e965c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a7e1b5f778485e912aa633abda75ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae98ac435aff4275b7dfb3332ede5878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a6d9daa96d426b9cb2536a7120fdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732637bfa4bd46f5b9206d38a64a1166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74be1708b8814b9889e42f63dff3adc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452bdde6977a4ebb89e5c594e811c8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2658dfb0ed9e44f0b9f09e62cc578ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747b49a0ddf64f78905b011eb56911bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a88b01e4044504a95d63adc6429e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dca09cbd73494489a326e55a4d5b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dddd5858b54e16b967a35ac770d1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7771ffc10141779a4a689952f8c502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6575bf724314c51b293c6dff4a46977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3a6accf13e41df882f6095bcaacc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ddf7caf6eb4db2ac55c5fb1dcea4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72cf179cc9f049ac8db829f036d3cb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0b34165d9e46e0b6682d6139b54393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ebb4f4bb994027ab8f20dc127cb451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9069805417e342d3a298ea755b2de9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52edf1246a7848fda728bb999af96312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b34322ab0a4582b43a0eab7b715af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07356a1ab6324f6196c8d8234dfcbf7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaa0664f927474080e387d92d704390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b447f46a76c740d28d0de6383e42cf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3478d5b1eea458abb220d705b62f21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8c24238a274c2ba6a971f3bc80003f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0762e6cc77143e88df642662d270a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134c38b2d0784aa99c57da51b85c3947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbbf9716f0d41dba5d8880c46e54def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "push_to_hf(\"MMLU\", mmlu_auxiliary_data, mmlu_validation_data)\n",
    "push_to_hf(\"MMLU-PRO\", mmlu_stem_10, mmlu_validation_data_10)\n",
    "push_to_hf(\"ARC-Easy\", arc_easy_data, arc_easy_data_validation)\n",
    "push_to_hf(\"ARC-Challenge\", arc_challenge_data, arc_challenge_data_validation)\n",
    "push_to_hf(\"ScienceQA\", scienceqa_data, scienceqa_data_validation)\n",
    "push_to_hf(\"MathQA\", mathqa_data, mathqa_data_validation)\n",
    "push_to_hf(\"OpenBookQA\", openbookqa_data, openbookqa_data_validation)\n",
    "push_to_hf(\"SciQ\", sciq_data_train, sciq_data_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLNP Project",
   "language": "python",
   "name": "mnlp_m2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
